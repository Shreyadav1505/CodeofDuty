{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T18:22:24.163721Z","iopub.status.busy":"2023-11-20T18:22:24.163022Z","iopub.status.idle":"2023-11-20T18:22:25.908010Z","shell.execute_reply":"2023-11-20T18:22:25.906916Z","shell.execute_reply.started":"2023-11-20T18:22:24.163665Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd \n","import torch\n","import torch.nn as nn\n","import cv2\n","import os\n","import time\n","from torch.autograd import Variable\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T18:22:25.910632Z","iopub.status.busy":"2023-11-20T18:22:25.910285Z","iopub.status.idle":"2023-11-20T18:22:38.280065Z","shell.execute_reply":"2023-11-20T18:22:38.279013Z","shell.execute_reply.started":"2023-11-20T18:22:25.910581Z"},"trusted":true},"outputs":[],"source":["!pip install sentence_transformers"]},{"cell_type":"markdown","metadata":{},"source":["# **YOLO MODEL**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T18:22:38.282665Z","iopub.status.busy":"2023-11-20T18:22:38.282203Z","iopub.status.idle":"2023-11-20T18:22:38.289157Z","shell.execute_reply":"2023-11-20T18:22:38.288001Z","shell.execute_reply.started":"2023-11-20T18:22:38.282597Z"},"trusted":true},"outputs":[],"source":["#getting weights from pretrained model\n","weightsfile = '/kaggle/input/data-for-yolo-v3-kernel/yolov3.weights'\n","classfile = '/kaggle/input/data-for-yolo-v3-kernel/coco.names'\n","cfgfile = '/kaggle/working/yolov3.cfg'\n","sample_img1 = '/kaggle/working/input/insta20881.jpg'\n","input_dir = '/kaggle/working/input'\n","output_dir = '/kaggle/working/output'\n","nms_thesh = 0.5"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T18:22:38.291409Z","iopub.status.busy":"2023-11-20T18:22:38.291027Z","iopub.status.idle":"2023-11-20T18:22:38.306376Z","shell.execute_reply":"2023-11-20T18:22:38.305175Z","shell.execute_reply.started":"2023-11-20T18:22:38.291359Z"},"trusted":true},"outputs":[],"source":["if not os.path.exists(input_dir):\n","    os.mkdir(input_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T18:22:38.311585Z","iopub.status.busy":"2023-11-20T18:22:38.311127Z","iopub.status.idle":"2023-11-20T18:22:40.940461Z","shell.execute_reply":"2023-11-20T18:22:40.939119Z","shell.execute_reply.started":"2023-11-20T18:22:38.311540Z"},"trusted":true},"outputs":[],"source":["! wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n","! cp /kaggle/input/instagram-images-with-captions/instagram_data2/img2/insta20881.jpg /kaggle/working/input"]},{"cell_type":"markdown","metadata":{},"source":["We will create the model using the configuration file.First we will parse it and then feed to our model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T18:22:40.943109Z","iopub.status.busy":"2023-11-20T18:22:40.942730Z","iopub.status.idle":"2023-11-20T18:22:40.956512Z","shell.execute_reply":"2023-11-20T18:22:40.955382Z","shell.execute_reply.started":"2023-11-20T18:22:40.943066Z"},"trusted":true},"outputs":[],"source":["def parse_cfg(config_file):\n","    file = open(config_file,'r')\n","    file = file.read().split('\\n')\n","    file =  [line for line in file if len(line)>0 and line[0] != '#']\n","    file = [line.lstrip().rstrip() for line in file]\n","\n","    final_list = []\n","    element_dict = {}\n","    for line in file:\n","\n","        if line[0] == '[':\n","            if len(element_dict) != 0:     # appending the dict stored on previous iteration\n","                    final_list.append(element_dict)\n","                    element_dict = {} # again emtying dict\n","            element_dict['type'] = ''.join([i for i in line if i != '[' and i != ']'])\n","            \n","        else:\n","            val = line.split('=')\n","            element_dict[val[0].rstrip()] = val[1].lstrip()  #removing spaces on left and right side\n","        \n","    final_list.append(element_dict) # appending the values stored for last set\n","    return final_list"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T18:22:40.958488Z","iopub.status.busy":"2023-11-20T18:22:40.958130Z","iopub.status.idle":"2023-11-20T18:22:41.088781Z","shell.execute_reply":"2023-11-20T18:22:41.087516Z","shell.execute_reply.started":"2023-11-20T18:22:40.958439Z"},"trusted":true},"outputs":[],"source":["class DummyLayer(nn.Module):\n","    def __init__(self):\n","        super(DummyLayer, self).__init__()\n","        \n","\n","        \n","class DetectionLayer(nn.Module):\n","    def __init__(self, anchors):\n","        super(DetectionLayer, self).__init__()\n","        self.anchors = anchors\n","        \n","        \n","\n","def create_model(blocks):\n","    darknet_details = blocks[0]\n","    channels = 3 \n","    output_filters = []\n","    modulelist = nn.ModuleList()\n","    for i,block in enumerate(blocks[1:]):\n","        seq = nn.Sequential()\n","        if (block[\"type\"] == \"convolutional\"):\n","            activation = block[\"activation\"]\n","            filters = int(block[\"filters\"])\n","            kernel_size = int(block[\"size\"])\n","            strides = int(block[\"stride\"])\n","            use_bias= False if (\"batch_normalize\" in block) else True\n","            pad = (kernel_size - 1) // 2\n","            \n","            conv = nn.Conv2d(in_channels=channels, out_channels=filters, kernel_size=kernel_size, \n","                             stride=strides, padding=pad, bias = use_bias)\n","            seq.add_module(\"conv_{0}\".format(i), conv)\n","            \n","            if \"batch_normalize\" in block:\n","                bn = nn.BatchNorm2d(filters)\n","                seq.add_module(\"batch_norm_{0}\".format(i), bn)\n","\n","            if activation == \"leaky\":\n","                activn = nn.LeakyReLU(0.1, inplace = True)\n","                seq.add_module(\"leaky_{0}\".format(i), activn)\n","            \n","        elif (block[\"type\"] == \"upsample\"):\n","            upsample = nn.Upsample(scale_factor = 2, mode = \"bilinear\")\n","            seq.add_module(\"upsample_{}\".format(i), upsample)\n","        \n","        elif (block[\"type\"] == 'route'):\n","\n","            block['layers'] = block['layers'].split(',')\n","            block['layers'][0] = int(block['layers'][0])\n","            start = block['layers'][0]\n","            if len(block['layers']) == 1:               \n","                filters = output_filters[i + start]\n","                       \n","            \n","            elif len(block['layers']) > 1:\n","                block['layers'][1] = int(block['layers'][1]) - i \n","                end = block['layers'][1]\n","                filters = output_filters[i + start] + output_filters[i + end]\n","                  \n","            \n","            route = DummyLayer()\n","            seq.add_module(\"route_{0}\".format(i),route)\n","      \n","        elif block[\"type\"] == \"shortcut\":\n","            from_ = int(block[\"from\"])\n","            shortcut = DummyLayer()\n","            seq.add_module(\"shortcut_{0}\".format(i),shortcut)\n","            \n","            \n","        elif block[\"type\"] == \"yolo\":\n","            mask = block[\"mask\"].split(\",\")\n","            mask = [int(m) for m in mask]\n","            anchors = block[\"anchors\"].split(\",\")\n","            anchors = [(int(anchors[i]), int(anchors[i + 1])) for i in range(0, len(anchors), 2)]\n","            anchors = [anchors[i] for i in mask]\n","            block[\"anchors\"] = anchors\n","            \n","            detectorLayer = DetectionLayer(anchors)\n","            seq.add_module(\"Detection_{0}\".format(i),detectorLayer)\n","                \n","        modulelist.append(seq)\n","        output_filters.append(filters)  \n","        channels = filters\n","    \n","    return darknet_details, modulelist\n","    "]},{"cell_type":"markdown","metadata":{},"source":["# Creating Yolo Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T18:22:41.090642Z","iopub.status.busy":"2023-11-20T18:22:41.090315Z","iopub.status.idle":"2023-11-20T18:22:41.115721Z","shell.execute_reply":"2023-11-20T18:22:41.114675Z","shell.execute_reply.started":"2023-11-20T18:22:41.090608Z"},"trusted":true},"outputs":[],"source":["def prediction(x,inp_dim,anchors,num_classes,CUDA=False):\n","    batch_size = x.size(0)\n","    grid_size = x.size(2)\n","    stride =  inp_dim // x.size(2)   \n","    \n","    bbox_attrs = 5 + num_classes\n","    num_anchors = len(anchors)\n","    prediction = x.view(batch_size, bbox_attrs*num_anchors, grid_size*grid_size)\n","    prediction = prediction.transpose(1,2).contiguous()\n","    prediction = prediction.view(batch_size, grid_size*grid_size*num_anchors, bbox_attrs)\n","    \n","    \n","    anchors = [(a[0]/stride, a[1]/stride) for a in anchors]\n","\n","    prediction[:,:,0] = torch.sigmoid(prediction[:,:,0])\n","    prediction[:,:,1] = torch.sigmoid(prediction[:,:,1])\n","    prediction[:,:,4] = torch.sigmoid(prediction[:,:,4])\n","    grid = np.arange(grid_size)\n","    a,b = np.meshgrid(grid, grid)\n","\n","    x_offset = torch.FloatTensor(a).view(-1,1)\n","    y_offset = torch.FloatTensor(b).view(-1,1)\n","\n","    if CUDA:\n","        x_offset = x_offset.cuda()\n","        y_offset = y_offset.cuda()\n","\n","    x_y_offset = torch.cat((x_offset, y_offset), 1).repeat(1,num_anchors).view(-1,2).unsqueeze(0)\n","    \n","\n","    prediction[:,:,:2] += x_y_offset\n","\n","    \n","    anchors = torch.FloatTensor(anchors)\n","\n","    if CUDA:\n","        anchors = anchors.cuda()\n","\n","    anchors = anchors.repeat(grid_size*grid_size, 1).unsqueeze(0)\n","    prediction[:,:,2:4] = torch.exp(prediction[:,:,2:4])*anchors \n","    prediction[:,:,5: 5 + num_classes] = torch.sigmoid((prediction[:,:, 5 : 5 + num_classes]))    \n","    prediction[:,:,:4] *= stride    \n","    return prediction\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T18:22:41.118680Z","iopub.status.busy":"2023-11-20T18:22:41.118217Z","iopub.status.idle":"2023-11-20T18:22:41.167836Z","shell.execute_reply":"2023-11-20T18:22:41.166383Z","shell.execute_reply.started":"2023-11-20T18:22:41.118630Z"},"trusted":true},"outputs":[],"source":["class Darknet(nn.Module):\n","    def __init__(self, cfgfile):\n","        super(Darknet, self).__init__()\n","        self.blocks = parse_cfg(cfgfile)\n","        self.net_info, self.module_list = create_model(self.blocks)\n","        \n","    def forward(self, x, CUDA=False):\n","        modules = self.blocks[1:]\n","        outputs = {}  \n","        \n","        write = 0    \n","        \n","        for i, module in enumerate(modules):        \n","            module_type = (module[\"type\"])\n","            if module_type == \"convolutional\" or module_type == \"upsample\":\n","                x = self.module_list[i](x)\n","                outputs[i] = x\n","                \n","            elif module_type == \"route\":\n","                layers = module[\"layers\"]\n","                layers = [int(a) for a in layers]\n","                if len(layers) == 1:\n","                    x = outputs[i + layers[0]]\n","                if len(layers) > 1:\n","                    map1 = outputs[i + layers[0]]\n","                    map2 = outputs[i + layers[1]]\n","                    x = torch.cat((map1,map2),1)\n","       \n","                outputs[i] = x\n","                \n","            elif  module_type == \"shortcut\":\n","                from_ = int(module[\"from\"])\n","\n","     \n","                x = outputs[i-1] + outputs[i+from_]  \n","                outputs[i] = x\n","                \n","            elif module_type == 'yolo':\n","                anchors = self.module_list[i][0].anchors\n","                \n","                \n","                inp_dim = int(self.net_info[\"height\"])\n","                \n","                num_classes = int(module[\"classes\"])\n","\n","                \n","                x = x.data   \n","                x = prediction(x,inp_dim,anchors,num_classes)\n","                \n","                if not write:              \n","                    detections = x\n","                    write = 1\n","                else:       \n","                    detections = torch.cat((detections, x), 1)\n","\n","                outputs[i] = outputs[i-1]\n","                \n","        try:\n","            return detections   \n","        except:\n","            return 0\n","    \n","    def load_weights(self, weightfile):\n","        \n","        \n","        fp = open(weightfile, \"rb\")\n","\n","        header = np.fromfile(fp, dtype = np.int32, count = 5)\n","        self.header = torch.from_numpy(header)\n","        self.seen = self.header[3]\n","        \n","        weights = np.fromfile(fp, dtype = np.float32)\n","        \n","        ptr = 0\n","        for i in range(len(self.module_list)):\n","            module_type = self.blocks[i + 1][\"type\"]\n","            \n","            if module_type == \"convolutional\":\n","                model = self.module_list[i]\n","                try:\n","                    batch_normalize = int(self.blocks[i+1][\"batch_normalize\"])\n","                except:\n","                    batch_normalize = 0\n","                \n","                conv = model[0]\n","                \n","                if (batch_normalize):\n","                    bn = model[1]\n","                    \n","                    \n","                    num_bn_biases = bn.bias.numel()\n","                    \n","                    \n","                    bn_biases = torch.from_numpy(weights[ptr:ptr + num_bn_biases])\n","                    ptr += num_bn_biases\n","                    \n","                    bn_weights = torch.from_numpy(weights[ptr: ptr + num_bn_biases])\n","                    ptr  += num_bn_biases\n","                    \n","                    bn_running_mean = torch.from_numpy(weights[ptr: ptr + num_bn_biases])\n","                    ptr  += num_bn_biases\n","                    \n","                    bn_running_var = torch.from_numpy(weights[ptr: ptr + num_bn_biases])\n","                    ptr  += num_bn_biases\n","                    \n","                    bn_biases = bn_biases.view_as(bn.bias.data)\n","                    bn_weights = bn_weights.view_as(bn.weight.data)\n","                    bn_running_mean = bn_running_mean.view_as(bn.running_mean)\n","                    bn_running_var = bn_running_var.view_as(bn.running_var)\n","\n","                    bn.bias.data.copy_(bn_biases)\n","                    bn.weight.data.copy_(bn_weights)\n","                    bn.running_mean.copy_(bn_running_mean)\n","                    bn.running_var.copy_(bn_running_var)\n","                \n","                else:\n","                    num_biases = conv.bias.numel()\n","                \n","                    conv_biases = torch.from_numpy(weights[ptr: ptr + num_biases])\n","                    ptr = ptr + num_biases\n","                    \n","                    \n","                    conv_biases = conv_biases.view_as(conv.bias.data)\n","                \n","                    conv.bias.data.copy_(conv_biases)\n","                    \n","                num_weights = conv.weight.numel()\n","                \n","                conv_weights = torch.from_numpy(weights[ptr:ptr+num_weights])\n","                ptr = ptr + num_weights\n","\n","                conv_weights = conv_weights.view_as(conv.weight.data)\n","                conv.weight.data.copy_(conv_weights)"]},{"cell_type":"markdown","metadata":{},"source":["# YOLO Predictions "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T18:22:41.170119Z","iopub.status.busy":"2023-11-20T18:22:41.169746Z","iopub.status.idle":"2023-11-20T18:22:41.218160Z","shell.execute_reply":"2023-11-20T18:22:41.216677Z","shell.execute_reply.started":"2023-11-20T18:22:41.170080Z"},"trusted":true},"outputs":[],"source":["def bbox_iou(box1, box2):\n","\n","    b1_x1, b1_y1, b1_x2, b1_y2 = box1[:,0], box1[:,1], box1[:,2], box1[:,3]\n","    b2_x1, b2_y1, b2_x2, b2_y2 = box2[:,0], box2[:,1], box2[:,2], box2[:,3]\n","    \n","    inter_rect_x1 =  torch.max(b1_x1, b2_x1)\n","    inter_rect_y1 =  torch.max(b1_y1, b2_y1)\n","    inter_rect_x2 =  torch.min(b1_x2, b2_x2)\n","    inter_rect_y2 =  torch.min(b1_y2, b2_y2)\n","\n","    inter_area = torch.clamp(inter_rect_x2 - inter_rect_x1 + 1, min=0) * torch.clamp(inter_rect_y2 - inter_rect_y1 + 1, min=0)\n"," \n","    b1_area = (b1_x2 - b1_x1 + 1)*(b1_y2 - b1_y1 + 1)\n","    b2_area = (b2_x2 - b2_x1 + 1)*(b2_y2 - b2_y1 + 1)\n","    \n","    iou = inter_area / (b1_area + b2_area - inter_area)\n","    \n","    return iou\n","\n","\n","def unique(tensor):\n","    tensor_np = tensor.cpu().numpy()\n","    unique_np = np.unique(tensor_np)\n","    unique_tensor = torch.from_numpy(unique_np)\n","    \n","    tensor_res = tensor.new(unique_tensor.shape)\n","    tensor_res.copy_(unique_tensor)\n","    return tensor_res\n","\n","def write_results(prediction, confidence, num_classes, nms_conf = 0.4):\n","\n","    conf_mask = (prediction[:,:,4] > confidence).float().unsqueeze(2)\n","    prediction = prediction*conf_mask\n","    \n","    box_corner = prediction.new(prediction.shape)\n","    box_corner[:,:,0] = (prediction[:,:,0] - prediction[:,:,2]/2)\n","    box_corner[:,:,1] = (prediction[:,:,1] - prediction[:,:,3]/2)\n","    box_corner[:,:,2] = (prediction[:,:,0] + prediction[:,:,2]/2) \n","    box_corner[:,:,3] = (prediction[:,:,1] + prediction[:,:,3]/2)\n","    prediction[:,:,:4] = box_corner[:,:,:4]\n","    \n","    batch_size = prediction.size(0)\n","    write = False\n","    \n","    for ind in range(batch_size):  \n","        image_pred = prediction[ind] \n","        max_conf, max_conf_score = torch.max(image_pred[:,5:5+ num_classes], 1)\n","        max_conf = max_conf.float().unsqueeze(1)\n","        max_conf_score = max_conf_score.float().unsqueeze(1)\n","        seq = (image_pred[:,:5], max_conf, max_conf_score)\n","    \n","        image_pred = torch.cat(seq, 1) \n","        \n","        non_zero_ind =  (torch.nonzero(image_pred[:,4])) \n","        image_pred_ = image_pred[non_zero_ind.squeeze(),:].view(-1,7)\n","        try:\n","            \n","            img_classes = unique(image_pred_[:,-1]) \n","        except:\n","             continue\n","    \n","        for cls in img_classes:\n","            \n","            cls_mask = image_pred_*(image_pred_[:,-1] == cls).float().unsqueeze(1)\n","            class_mask_ind = torch.nonzero(cls_mask[:,-2]).squeeze()\n","            image_pred_class = image_pred_[class_mask_ind].view(-1,7)\n","            \n","            \n","            conf_sort_index = torch.sort(image_pred_class[:,4], descending = True )[1]\n","            image_pred_class = image_pred_class[conf_sort_index]\n","            idx = image_pred_class.size(0)\n","            \n","            for i in range(idx):\n","                \n","                try:\n","                    ious = bbox_iou(image_pred_class[i].unsqueeze(0), image_pred_class[i+1:])\n","                except ValueError:\n","                    break\n","                except IndexError:\n","                    break\n","                \n","               \n","                iou_mask = (ious < nms_conf).float().unsqueeze(1)\n","                image_pred_class[i+1:] *= iou_mask\n","                \n","          \n","                non_zero_ind = torch.nonzero(image_pred_class[:,4]).squeeze()\n","                image_pred_class = image_pred_class[non_zero_ind].view(-1,7)\n","          \n","           \n","            batch_ind = image_pred_class.new(image_pred_class.size(0), 1).fill_(ind)\n","            seq = batch_ind, image_pred_class\n","            if not write:\n","                output = torch.cat(seq,1)\n","                write = True\n","            else:\n","                out = torch.cat(seq,1)\n","                output = torch.cat((output,out))\n","    \n","    return output\n","            "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T18:22:41.220654Z","iopub.status.busy":"2023-11-20T18:22:41.220244Z","iopub.status.idle":"2023-11-20T18:22:41.240258Z","shell.execute_reply":"2023-11-20T18:22:41.238907Z","shell.execute_reply.started":"2023-11-20T18:22:41.220605Z"},"trusted":true},"outputs":[],"source":["\n","def load_classes(namesfile):\n","    '''outputs a dicionary wthat has its keys as class indices and their names as strings as values. '''\n","    fp = open(namesfile, \"r\")\n","    names = fp.read().split(\"\\n\")[:-1]\n","    return names\n","\n","\n","def prep_image(img, inp_dim):\n","\n","    orig_im = cv2.imread(img)\n","    dim = orig_im.shape[1], orig_im.shape[0]\n","    img = (letterbox_image(orig_im, (inp_dim, inp_dim)))\n","    img_ = img[:,:,::-1].transpose((2,0,1)).copy()\n","    img_ = torch.from_numpy(img_).float().div(255.0).unsqueeze(0)\n","    return img_, orig_im, dim\n","\n","def letterbox_image(img, inp_dim):\n","    \n","    img_w, img_h = img.shape[1], img.shape[0]\n","    w, h = inp_dim\n","    new_w = int(img_w * min(w/img_w, h/img_h))\n","    new_h = int(img_h * min(w/img_w, h/img_h))\n","    resized_image = cv2.resize(img, (new_w,new_h), interpolation = cv2.INTER_CUBIC)\n","    \n","    canvas = np.full((inp_dim[1], inp_dim[0], 3), 128)\n","\n","    canvas[(h-new_h)//2:(h-new_h)//2 + new_h,(w-new_w)//2:(w-new_w)//2 + new_w,:] = resized_image\n","    \n","    return canvas"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T18:22:41.242173Z","iopub.status.busy":"2023-11-20T18:22:41.241876Z","iopub.status.idle":"2023-11-20T18:22:46.877645Z","shell.execute_reply":"2023-11-20T18:22:46.872907Z","shell.execute_reply.started":"2023-11-20T18:22:41.242138Z"},"trusted":true},"outputs":[],"source":["CUDA = False\n","batch_size = 2\n","print(\"Loading network.....\")\n","model = Darknet(cfgfile)\n","model.load_weights(weightsfile)\n","print(\"Network successfully loaded\")\n","classes = load_classes(classfile)\n","print('Classes loaded')\n","inp_dim = int(model.net_info[\"height\"])\n","assert inp_dim % 32 == 0 \n","assert inp_dim > 32\n","query=''\n","\n","if CUDA:\n","    model.cuda()\n","\n","model.eval()\n","\n","read_dir = time.time()\n","\n","try:\n","    imlist = [os.path.join(os.path.realpath('.'), input_dir, img) for img in os.listdir(input_dir)]\n","except NotADirectoryError:\n","    imlist = []\n","    imlist.append(os.path.join(os.path.realpath('.'), input_dir))\n","except FileNotFoundError:\n","    print (\"No file or directory with the name {}\".format(input_dir))\n","    exit()\n","    \n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","    \n","load_batch = time.time()\n","\n","\n","batches = list(map(prep_image, imlist, [inp_dim for x in range(len(imlist))]))\n","im_batches = [x[0] for x in batches] \n","orig_ims = [x[1] for x in batches] \n","im_dim_list = [x[2] for x in batches] \n","im_dim_list = torch.FloatTensor(im_dim_list).repeat(1,2) \n","    \n","    \n","if CUDA:\n","    im_dim_list = im_dim_list.cuda()\n","\n","    \n","    \n","reminder = 0\n","if (len(im_dim_list) % batch_size): \n","    reminder = 1\n","\n","if batch_size != 1:\n","    num_batches = len(imlist) // batch_size + reminder            \n","    im_batches = [torch.cat((im_batches[i*batch_size : min((i +  1)*batch_size,len(im_batches))])) \n","                 for i in range(num_batches)] \n","    \n","    \n","i = 0\n","write = False\n","    \n","objs = {}    \n","\n","for batch in im_batches:\n","\n","        start = time.time()\n","        if CUDA:\n","            batch = batch.cuda()       \n","    \n","        with torch.no_grad():\n","            prediction = model(Variable(batch), CUDA)\n","        \n","        prediction = write_results(prediction, confidence=0.5, num_classes=80, nms_conf = nms_thesh)\n","        \n","        if type(prediction) == int:\n","            i += 1\n","            continue\n","\n","\n","        prediction[:,0] += i*batch_size\n","                  \n","        if not write:\n","            output = prediction\n","            write = 1\n","        else:\n","            output = torch.cat((output,prediction))  \n","        i += 1\n","        \n","        if CUDA:\n","            torch.cuda.synchronize()\n","    \n","try:\n","    output\n","except NameError:\n","    print(\"No detections were made\")\n","    exit()\n","\n","\n","\n","im_dim_list = torch.index_select(im_dim_list, 0, output[:,0].long())\n","scaling_factor = torch.min(inp_dim/im_dim_list,1)[0].view(-1,1)\n","output[:,[1,3]] -= (inp_dim - scaling_factor*im_dim_list[:,0].view(-1,1))/2\n","output[:,[2,4]] -= (inp_dim - scaling_factor*im_dim_list[:,1].view(-1,1))/2\n","output[:,1:5] /= scaling_factor\n","    \n","for i in range(output.shape[0]):\n","    output[i, [1,3]] = torch.clamp(output[i, [1,3]], 0.0, im_dim_list[i,0])\n","    output[i, [2,4]] = torch.clamp(output[i, [2,4]], 0.0, im_dim_list[i,1])\n","    \n","def getLabels(labels):\n","    global query\n","    query=labels\n","    \n","\n","def write(x, batches, results):\n","    c1 = tuple(x[1:3].int())\n","    c2 = tuple(x[3:5].int())\n","    img = results[int(x[0])]\n","    cls = int(x[-1])\n","    label = \"{0}\".format(classes[cls])\n","    color = (0,0,255)\n","    cv2.rectangle(img, c1, c2,color, 2)\n","    t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, 1 , 1)[0]\n","    c2 = c1[0] + t_size[0] + 3, c1[1] + t_size[1] + 4\n","    cv2.rectangle(img, c1, c2,color, -1)\n","    cv2.putText(img, label, (c1[0], c1[1] + t_size[1] + 4), cv2.FONT_HERSHEY_PLAIN, 1, [225,255,255], 1)\n","    getLabels(label)\n","    return img\n","    \n","            \n","list(map(lambda x: write(x, im_batches, orig_ims), output))\n","      \n","det_names = pd.Series(imlist).apply(lambda x: \"{}/det_{}\".format(output_dir,x.split(\"/\")[-1]))\n","    \n","list(map(cv2.imwrite, det_names, orig_ims))\n","\n","    \n","\n","torch.cuda.empty_cache()\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T18:22:46.884839Z","iopub.status.busy":"2023-11-20T18:22:46.883370Z","iopub.status.idle":"2023-11-20T18:22:47.443496Z","shell.execute_reply":"2023-11-20T18:22:47.441773Z","shell.execute_reply.started":"2023-11-20T18:22:46.884743Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["img = cv2.imread('/kaggle/working/output/det_insta20881.jpg') \n","img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n","plt.figure(figsize=(20,10))\n","plt.imshow(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T18:22:47.446484Z","iopub.status.busy":"2023-11-20T18:22:47.446006Z","iopub.status.idle":"2023-11-20T18:22:47.453951Z","shell.execute_reply":"2023-11-20T18:22:47.452503Z","shell.execute_reply.started":"2023-11-20T18:22:47.446416Z"},"trusted":true},"outputs":[],"source":["print (query)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T18:22:59.159871Z","iopub.status.busy":"2023-11-20T18:22:59.159542Z","iopub.status.idle":"2023-11-20T18:23:05.049111Z","shell.execute_reply":"2023-11-20T18:23:05.047820Z","shell.execute_reply.started":"2023-11-20T18:22:59.159818Z"},"trusted":true},"outputs":[],"source":["#%pip install openai"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T18:23:05.051495Z","iopub.status.busy":"2023-11-20T18:23:05.051058Z","iopub.status.idle":"2023-11-20T18:23:08.916060Z","shell.execute_reply":"2023-11-20T18:23:08.914767Z","shell.execute_reply.started":"2023-11-20T18:23:05.051422Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":81753,"sourceId":300187,"sourceType":"datasetVersion"},{"datasetId":526463,"sourceId":1025327,"sourceType":"datasetVersion"}],"dockerImageVersionId":29867,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}
